{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods\n",
    "\n",
    "### Folders\n",
    "* Model folder: word2vec model and DNN model (with accuracy of 18%~19%)\n",
    "* Cnnmodel folder: CNN model (with acuracy of 28%~30%)\n",
    "* Rnnmodel folder: LSTM model (with accuracy of 39%~40%)\n",
    "\n",
    "\n",
    "### Scripts\n",
    "* *handle_json.py* - The original lines.json file contains all lines from the show \"Friends\", which was in JSON format, we converted the character names into numbers and write them into data/feature_raw.txt. We also pick only the 6 main characters' lines (6 main characters: Ross, Rachel, Joey, Chandler, Monica and Phoebe).\n",
    "\n",
    "\n",
    "* *extract_label_and_sentence.py* - Extract labels from data/feature_raw.txt and write them into data/label.txt, also extract the segmantations into data/sentence.txt.\n",
    "\n",
    "\n",
    "* *extract_feature.py* - Train word vectors using word2vec (4 dimensions) and calculate the feature vectors of each sentence (take the average of the word vectors in each sentence), then write feature vectors into data/feature.txt. This process is mainly for DNN training because CNN and LSTM use embedding which doesn't train word vector the same way.\n",
    "\n",
    "\n",
    "* *main_word2vec.py* - DNN with 3 hidden layers. The neuron numbers of each layer is 40, 20 and 10, respectively. The input dimension is 4 (4 features) and the output dimension is 6 (6 characters). The first 2 layersâ€˜ activation function is sigmoid and the last layer's is softmax. The learning rate is 0.0001 and there are 1000 iterations. Note that there is a parameter, is_train, in the model, if is_train is True, it starts to train a new model, otherwise it takes the trained model.\n",
    "\n",
    "\n",
    "* *main.py* - Similar to main_word2vec.py, but it is DNN with embedding.\n",
    "\n",
    "\n",
    "* *data_helpers.py* - Helps to batch process the data\n",
    "\n",
    "\n",
    "* *cnn_model.py* - CNN with an embedding layer (100 dimensions word vectos), a CNN layer, a pool layer and a softmax layer to output the probability of each label.\n",
    "\n",
    "\n",
    "* *textCNN.py* - It takes the cnn_model.py to train or test the lines data. It takes 90% of the lines for training and 10% of them for testing. The accuracy is 28%~30%. The learn rate is 0.0001.\n",
    "\n",
    "* *textRNN.py* - RNN with an embedding layer, a bi-lstm layer, a concat layer, a fully connected layer and a softmax layer. It takes 90% of the lines for training and 10% of them for testing. The accuracy is 39%~40%. The learn rate is 0.0001.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### handle_json.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Monica': 4213, 'Joey': 4308, 'Phoebe': 3795, 'Chandler': 4235, 'Ross': 4475, 'Rachel': 4641}\n",
      "Now there are 88.88388683034941% lines left, 6 people left.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def main():\n",
    "  dict = {}\n",
    "  select = {}   # select the characters\n",
    "\n",
    "  with open('lines.json', 'r', encoding='utf-8') as f:\n",
    "    text = json.load(f)\n",
    "  for i in range(len(text)):\n",
    "    name = text[i]['character']\n",
    "    if name not in dict:\n",
    "      dict[name] = 1\n",
    "    else:\n",
    "      dict[name] += 1\n",
    "  line_left = 0\n",
    "  for k,v in dict.items():\n",
    "    if v > 1000:    # pick only the main characters who has more than 1000 lines\n",
    "      select[k] = v\n",
    "      line_left += v\n",
    "  print(select)\n",
    "\n",
    "  #print(select)\n",
    "  print(\"Now there are {}% lines left, {} people left.\".format(line_left/28877*100, len(select)))\n",
    "\n",
    "  # label with numbers\n",
    "  label = {}\n",
    "  now_label = 0\n",
    "  for k,v in select.items():\n",
    "    if k in label:\n",
    "      continue\n",
    "    label[k] = now_label\n",
    "    now_label += 1\n",
    "\n",
    "  # write it to feature_raw.txt file (label + sentence)\n",
    "  with open('data/feature_raw.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in range(len(text)):\n",
    "      name = text[i]['character']\n",
    "      sentence = text[i]['text']\n",
    "      if name in select:\n",
    "        f.write(str(label[name]) + '\\t')\n",
    "        f.write(sentence + '\\n')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract_label_and_sentence.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer  \n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "punctuation = string.punctuation\n",
    "\n",
    "# Read the file\n",
    "def read_file(file):\n",
    "  with open(file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "  for i in range(len(lines)):\n",
    "    lines[i] = lines[i].strip()\n",
    "  return lines\n",
    "\n",
    "def get_label_and_sentence(content):\n",
    "  label, sentence = [], []\n",
    "  for i in range(len(content)):\n",
    "    seg = content[i].split()\n",
    "    label.append(int(seg[0]))   #labels\n",
    "\n",
    "    #take a line\n",
    "    sent = ' '.join(seg[1:])\n",
    "    words = WordPunctTokenizer().tokenize(sent)\n",
    "    this_sentence = []\n",
    "    for ele in words:\n",
    "      if (ele not in punctuation) and (ele not in stopwords):\n",
    "        this_sentence.append(ele)\n",
    "    sentence.append(this_sentence)\n",
    "\n",
    "  return label, sentence\n",
    "\n",
    "def main():\n",
    "  content = read_file(\"data/feature_raw.txt\")\n",
    "  label, sentence = get_label_and_sentence(content)   # Get labels and sentence list\n",
    "\n",
    "  # Write label\n",
    "  with open(\"data/label.txt\", 'w', encoding='utf-8') as f:\n",
    "    for i in range(len(label)):\n",
    "      f.write(str(label[i]) + '\\n')  \n",
    "  # Write lines\n",
    "  with open('data/sentence.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in range(len(sentence)):\n",
    "      for j in range(len(sentence[i])):\n",
    "        f.write(sentence[i][j])\n",
    "        if j != len(sentence[i])-1:\n",
    "          f.write('\\t')\n",
    "      f.write('\\n')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract_feature.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-25 00:43:37,927: INFO: collecting all words and their counts\n",
      "2018-03-25 00:43:37,929: INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-03-25 00:43:38,017: INFO: PROGRESS: at sentence #10000, processed 90100 words, keeping 8189 word types\n",
      "2018-03-25 00:43:38,099: INFO: PROGRESS: at sentence #20000, processed 180347 words, keeping 11504 word types\n",
      "2018-03-25 00:43:38,142: INFO: collected 13319 word types from a corpus of 230239 raw words and 25667 sentences\n",
      "2018-03-25 00:43:38,143: INFO: Loading a fresh vocabulary\n",
      "2018-03-25 00:43:38,198: INFO: min_count=1 retains 13319 unique words (100% of original 13319, drops 0)\n",
      "2018-03-25 00:43:38,205: INFO: min_count=1 leaves 230239 word corpus (100% of original 230239, drops 0)\n",
      "2018-03-25 00:43:38,298: INFO: deleting the raw counts dictionary of 13319 items\n",
      "2018-03-25 00:43:38,303: INFO: sample=0.001 downsamples 57 most-common words\n",
      "2018-03-25 00:43:38,305: INFO: downsampling leaves estimated 185858 word corpus (80.7% of prior 230239)\n",
      "2018-03-25 00:43:38,374: INFO: estimated required memory for 13319 words and 4 dimensions: 7085708 bytes\n",
      "2018-03-25 00:43:38,386: INFO: resetting layer weights\n",
      "2018-03-25 00:43:38,587: INFO: training model with 4 workers on 13319 vocabulary and 4 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-03-25 00:43:38,853: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:38,856: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:38,863: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:38,868: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:38,870: INFO: EPOCH - 1 : training on 230239 raw words (185600 effective words) took 0.3s, 661914 effective words/s\n",
      "2018-03-25 00:43:39,160: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:39,162: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:39,169: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:39,174: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:39,175: INFO: EPOCH - 2 : training on 230239 raw words (185844 effective words) took 0.3s, 617162 effective words/s\n",
      "2018-03-25 00:43:39,578: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:39,580: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:39,582: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:39,591: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:39,592: INFO: EPOCH - 3 : training on 230239 raw words (185796 effective words) took 0.4s, 448770 effective words/s\n",
      "2018-03-25 00:43:39,969: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:39,971: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:39,974: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:39,985: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:39,987: INFO: EPOCH - 4 : training on 230239 raw words (185734 effective words) took 0.4s, 473985 effective words/s\n",
      "2018-03-25 00:43:40,315: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:40,322: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:40,324: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:40,332: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:40,333: INFO: EPOCH - 5 : training on 230239 raw words (185637 effective words) took 0.3s, 541443 effective words/s\n",
      "2018-03-25 00:43:40,651: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:40,656: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:40,665: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:40,668: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:40,669: INFO: EPOCH - 6 : training on 230239 raw words (185828 effective words) took 0.3s, 558091 effective words/s\n",
      "2018-03-25 00:43:41,059: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:41,063: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:41,069: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:41,074: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:41,075: INFO: EPOCH - 7 : training on 230239 raw words (186056 effective words) took 0.4s, 462607 effective words/s\n",
      "2018-03-25 00:43:41,459: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:41,462: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:41,470: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:41,479: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:41,480: INFO: EPOCH - 8 : training on 230239 raw words (185910 effective words) took 0.4s, 463628 effective words/s\n",
      "2018-03-25 00:43:41,774: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:41,779: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:41,782: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:41,790: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:41,791: INFO: EPOCH - 9 : training on 230239 raw words (185958 effective words) took 0.3s, 602434 effective words/s\n",
      "2018-03-25 00:43:42,103: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:42,108: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:42,113: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:42,118: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:42,120: INFO: EPOCH - 10 : training on 230239 raw words (186097 effective words) took 0.3s, 573946 effective words/s\n",
      "2018-03-25 00:43:42,482: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:42,484: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:42,491: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:42,499: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:42,500: INFO: EPOCH - 11 : training on 230239 raw words (186044 effective words) took 0.3s, 545555 effective words/s\n",
      "2018-03-25 00:43:42,985: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:42,987: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:43,000: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:43,002: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:43,004: INFO: EPOCH - 12 : training on 230239 raw words (185703 effective words) took 0.5s, 370680 effective words/s\n",
      "2018-03-25 00:43:43,277: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:43,279: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:43,286: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:43,292: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:43,294: INFO: EPOCH - 13 : training on 230239 raw words (186018 effective words) took 0.3s, 651082 effective words/s\n",
      "2018-03-25 00:43:43,547: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:43,549: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:43,559: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:43,561: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:43,562: INFO: EPOCH - 14 : training on 230239 raw words (186017 effective words) took 0.3s, 702167 effective words/s\n",
      "2018-03-25 00:43:43,875: INFO: worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-25 00:43:43,887: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:43,895: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:43,902: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:43,904: INFO: EPOCH - 15 : training on 230239 raw words (185605 effective words) took 0.3s, 547825 effective words/s\n",
      "2018-03-25 00:43:44,249: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:44,251: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:44,257: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:44,262: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:44,263: INFO: EPOCH - 16 : training on 230239 raw words (185814 effective words) took 0.4s, 528408 effective words/s\n",
      "2018-03-25 00:43:44,520: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:44,522: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:44,529: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:44,535: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:44,536: INFO: EPOCH - 17 : training on 230239 raw words (185808 effective words) took 0.3s, 686471 effective words/s\n",
      "2018-03-25 00:43:44,799: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:44,801: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:44,812: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:44,813: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:44,815: INFO: EPOCH - 18 : training on 230239 raw words (185697 effective words) took 0.3s, 675261 effective words/s\n",
      "2018-03-25 00:43:45,076: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:45,078: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:45,087: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:45,089: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:45,090: INFO: EPOCH - 19 : training on 230239 raw words (185737 effective words) took 0.3s, 682479 effective words/s\n",
      "2018-03-25 00:43:45,405: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:45,413: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:45,418: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:45,420: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:45,421: INFO: EPOCH - 20 : training on 230239 raw words (185772 effective words) took 0.3s, 566975 effective words/s\n",
      "2018-03-25 00:43:45,689: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:45,699: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:45,708: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:45,714: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:45,717: INFO: EPOCH - 21 : training on 230239 raw words (185846 effective words) took 0.3s, 633851 effective words/s\n",
      "2018-03-25 00:43:46,041: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:46,043: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:46,045: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:46,049: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:46,051: INFO: EPOCH - 22 : training on 230239 raw words (185973 effective words) took 0.3s, 593751 effective words/s\n",
      "2018-03-25 00:43:46,306: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:46,308: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:46,314: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:46,320: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:46,321: INFO: EPOCH - 23 : training on 230239 raw words (185809 effective words) took 0.3s, 695452 effective words/s\n",
      "2018-03-25 00:43:46,640: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:46,642: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:46,647: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:46,657: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:46,658: INFO: EPOCH - 24 : training on 230239 raw words (185901 effective words) took 0.3s, 556284 effective words/s\n",
      "2018-03-25 00:43:46,986: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:46,991: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:46,996: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:47,001: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:47,003: INFO: EPOCH - 25 : training on 230239 raw words (185637 effective words) took 0.3s, 542887 effective words/s\n",
      "2018-03-25 00:43:47,332: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:47,338: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:47,343: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:47,346: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:47,347: INFO: EPOCH - 26 : training on 230239 raw words (185720 effective words) took 0.3s, 544611 effective words/s\n",
      "2018-03-25 00:43:47,594: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:47,596: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:47,606: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:47,611: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:47,613: INFO: EPOCH - 27 : training on 230239 raw words (185785 effective words) took 0.3s, 711447 effective words/s\n",
      "2018-03-25 00:43:47,894: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:47,896: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:47,905: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:47,906: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:47,908: INFO: EPOCH - 28 : training on 230239 raw words (185826 effective words) took 0.3s, 636563 effective words/s\n",
      "2018-03-25 00:43:48,252: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:48,258: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:48,267: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:48,270: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:48,271: INFO: EPOCH - 29 : training on 230239 raw words (185623 effective words) took 0.4s, 514733 effective words/s\n",
      "2018-03-25 00:43:48,542: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:48,545: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:48,553: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:48,556: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:48,558: INFO: EPOCH - 30 : training on 230239 raw words (186192 effective words) took 0.3s, 658372 effective words/s\n",
      "2018-03-25 00:43:48,840: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:48,848: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:48,850: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:48,853: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:48,854: INFO: EPOCH - 31 : training on 230239 raw words (185779 effective words) took 0.3s, 631614 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-25 00:43:49,121: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:49,124: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:49,135: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:49,136: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:49,138: INFO: EPOCH - 32 : training on 230239 raw words (185964 effective words) took 0.3s, 662376 effective words/s\n",
      "2018-03-25 00:43:49,689: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:49,691: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:49,693: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:49,706: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:49,708: INFO: EPOCH - 33 : training on 230239 raw words (185828 effective words) took 0.6s, 327790 effective words/s\n",
      "2018-03-25 00:43:50,029: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:50,032: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:50,034: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:50,042: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:50,045: INFO: EPOCH - 34 : training on 230239 raw words (185975 effective words) took 0.3s, 563971 effective words/s\n",
      "2018-03-25 00:43:50,495: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:50,499: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:50,525: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:50,530: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:50,532: INFO: EPOCH - 35 : training on 230239 raw words (186018 effective words) took 0.5s, 387329 effective words/s\n",
      "2018-03-25 00:43:50,924: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:50,938: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:50,944: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:50,947: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:50,949: INFO: EPOCH - 36 : training on 230239 raw words (185809 effective words) took 0.4s, 469120 effective words/s\n",
      "2018-03-25 00:43:51,414: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:51,419: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:51,422: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:51,434: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:51,436: INFO: EPOCH - 37 : training on 230239 raw words (185971 effective words) took 0.5s, 386410 effective words/s\n",
      "2018-03-25 00:43:51,794: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:51,796: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:51,799: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:51,810: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:51,812: INFO: EPOCH - 38 : training on 230239 raw words (185806 effective words) took 0.4s, 501896 effective words/s\n",
      "2018-03-25 00:43:52,143: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:52,145: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:52,150: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:52,158: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:52,160: INFO: EPOCH - 39 : training on 230239 raw words (185789 effective words) took 0.3s, 562977 effective words/s\n",
      "2018-03-25 00:43:52,466: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:52,469: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:52,473: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:52,479: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:52,480: INFO: EPOCH - 40 : training on 230239 raw words (185573 effective words) took 0.3s, 598333 effective words/s\n",
      "2018-03-25 00:43:53,170: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:53,176: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:53,182: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:53,189: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:53,190: INFO: EPOCH - 41 : training on 230239 raw words (185944 effective words) took 0.7s, 264236 effective words/s\n",
      "2018-03-25 00:43:53,446: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:53,449: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:53,451: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:53,459: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:53,461: INFO: EPOCH - 42 : training on 230239 raw words (185840 effective words) took 0.3s, 692464 effective words/s\n",
      "2018-03-25 00:43:53,845: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:53,847: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:53,849: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:53,857: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:53,859: INFO: EPOCH - 43 : training on 230239 raw words (185836 effective words) took 0.4s, 482940 effective words/s\n",
      "2018-03-25 00:43:54,140: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:54,143: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:54,151: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:54,157: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:54,158: INFO: EPOCH - 44 : training on 230239 raw words (185659 effective words) took 0.3s, 624708 effective words/s\n",
      "2018-03-25 00:43:54,441: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:54,444: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:54,452: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:54,458: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:54,460: INFO: EPOCH - 45 : training on 230239 raw words (185692 effective words) took 0.3s, 632188 effective words/s\n",
      "2018-03-25 00:43:54,783: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:54,784: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:54,795: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:54,797: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:54,798: INFO: EPOCH - 46 : training on 230239 raw words (185972 effective words) took 0.3s, 555941 effective words/s\n",
      "2018-03-25 00:43:55,106: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:55,108: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:55,113: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:55,120: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:55,122: INFO: EPOCH - 47 : training on 230239 raw words (185891 effective words) took 0.3s, 578533 effective words/s\n",
      "2018-03-25 00:43:55,394: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:55,397: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:55,403: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:55,410: INFO: worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-25 00:43:55,411: INFO: EPOCH - 48 : training on 230239 raw words (185833 effective words) took 0.3s, 662521 effective words/s\n",
      "2018-03-25 00:43:55,667: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:55,670: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:55,678: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:55,686: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:55,688: INFO: EPOCH - 49 : training on 230239 raw words (185859 effective words) took 0.3s, 680453 effective words/s\n",
      "2018-03-25 00:43:56,094: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:56,096: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:56,107: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:56,114: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:56,115: INFO: EPOCH - 50 : training on 230239 raw words (185884 effective words) took 0.4s, 440601 effective words/s\n",
      "2018-03-25 00:43:56,389: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:56,394: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:56,401: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:56,403: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:56,404: INFO: EPOCH - 51 : training on 230239 raw words (185613 effective words) took 0.3s, 655263 effective words/s\n",
      "2018-03-25 00:43:56,655: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:56,658: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:56,662: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:56,669: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:56,670: INFO: EPOCH - 52 : training on 230239 raw words (185843 effective words) took 0.3s, 706853 effective words/s\n",
      "2018-03-25 00:43:56,934: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:56,939: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:56,943: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:56,952: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:56,954: INFO: EPOCH - 53 : training on 230239 raw words (185776 effective words) took 0.3s, 673170 effective words/s\n",
      "2018-03-25 00:43:57,263: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:57,264: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:57,274: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:57,276: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:57,278: INFO: EPOCH - 54 : training on 230239 raw words (185845 effective words) took 0.3s, 579452 effective words/s\n",
      "2018-03-25 00:43:57,649: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:57,656: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:57,667: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:57,672: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:57,673: INFO: EPOCH - 55 : training on 230239 raw words (185690 effective words) took 0.4s, 478448 effective words/s\n",
      "2018-03-25 00:43:57,930: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:57,932: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:57,940: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:57,946: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:57,948: INFO: EPOCH - 56 : training on 230239 raw words (185666 effective words) took 0.3s, 682160 effective words/s\n",
      "2018-03-25 00:43:58,206: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:58,209: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:58,216: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:58,217: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:58,219: INFO: EPOCH - 57 : training on 230239 raw words (185829 effective words) took 0.3s, 702011 effective words/s\n",
      "2018-03-25 00:43:58,536: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:58,540: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:58,543: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:58,551: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:58,554: INFO: EPOCH - 58 : training on 230239 raw words (185712 effective words) took 0.3s, 559791 effective words/s\n",
      "2018-03-25 00:43:58,990: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:58,996: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:59,003: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:59,010: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:59,013: INFO: EPOCH - 59 : training on 230239 raw words (185761 effective words) took 0.5s, 412669 effective words/s\n",
      "2018-03-25 00:43:59,288: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:59,292: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:59,302: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:59,306: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:59,308: INFO: EPOCH - 60 : training on 230239 raw words (185924 effective words) took 0.3s, 660027 effective words/s\n",
      "2018-03-25 00:43:59,581: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:59,588: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:59,590: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:59,595: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:59,596: INFO: EPOCH - 61 : training on 230239 raw words (185640 effective words) took 0.3s, 673588 effective words/s\n",
      "2018-03-25 00:43:59,858: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:43:59,861: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:43:59,876: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:43:59,877: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:43:59,879: INFO: EPOCH - 62 : training on 230239 raw words (185736 effective words) took 0.3s, 679470 effective words/s\n",
      "2018-03-25 00:44:00,185: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:00,188: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:00,193: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:00,199: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:00,200: INFO: EPOCH - 63 : training on 230239 raw words (185978 effective words) took 0.3s, 590594 effective words/s\n",
      "2018-03-25 00:44:00,478: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:00,480: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:00,481: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:00,491: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:00,493: INFO: EPOCH - 64 : training on 230239 raw words (185820 effective words) took 0.3s, 641701 effective words/s\n",
      "2018-03-25 00:44:00,751: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:00,754: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:00,757: INFO: worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-25 00:44:00,766: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:00,768: INFO: EPOCH - 65 : training on 230239 raw words (186106 effective words) took 0.3s, 683401 effective words/s\n",
      "2018-03-25 00:44:01,078: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:01,081: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:01,084: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:01,094: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:01,096: INFO: EPOCH - 66 : training on 230239 raw words (185829 effective words) took 0.3s, 572053 effective words/s\n",
      "2018-03-25 00:44:01,379: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:01,381: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:01,382: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:01,391: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:01,394: INFO: EPOCH - 67 : training on 230239 raw words (185821 effective words) took 0.3s, 634868 effective words/s\n",
      "2018-03-25 00:44:01,713: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:01,717: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:01,730: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:01,734: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:01,737: INFO: EPOCH - 68 : training on 230239 raw words (185603 effective words) took 0.3s, 551794 effective words/s\n",
      "2018-03-25 00:44:02,011: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:02,013: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:02,018: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:02,028: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:02,030: INFO: EPOCH - 69 : training on 230239 raw words (185809 effective words) took 0.3s, 659570 effective words/s\n",
      "2018-03-25 00:44:02,285: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:02,287: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:02,299: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:02,302: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:02,303: INFO: EPOCH - 70 : training on 230239 raw words (185811 effective words) took 0.3s, 687948 effective words/s\n",
      "2018-03-25 00:44:02,566: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:02,568: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:02,575: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:02,585: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:02,587: INFO: EPOCH - 71 : training on 230239 raw words (185804 effective words) took 0.3s, 671759 effective words/s\n",
      "2018-03-25 00:44:03,016: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:03,018: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:03,031: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:03,035: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:03,037: INFO: EPOCH - 72 : training on 230239 raw words (185635 effective words) took 0.4s, 417961 effective words/s\n",
      "2018-03-25 00:44:03,363: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:03,364: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:03,372: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:03,375: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:03,376: INFO: EPOCH - 73 : training on 230239 raw words (185702 effective words) took 0.3s, 554314 effective words/s\n",
      "2018-03-25 00:44:03,639: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:03,646: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:03,652: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:03,658: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:03,659: INFO: EPOCH - 74 : training on 230239 raw words (185968 effective words) took 0.3s, 663552 effective words/s\n",
      "2018-03-25 00:44:03,916: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:03,921: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:03,923: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:03,928: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:03,930: INFO: EPOCH - 75 : training on 230239 raw words (185881 effective words) took 0.3s, 694455 effective words/s\n",
      "2018-03-25 00:44:04,260: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:04,262: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:04,265: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:04,274: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:04,275: INFO: EPOCH - 76 : training on 230239 raw words (185667 effective words) took 0.3s, 542548 effective words/s\n",
      "2018-03-25 00:44:04,565: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:04,566: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:04,567: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:04,577: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:04,579: INFO: EPOCH - 77 : training on 230239 raw words (186017 effective words) took 0.3s, 623469 effective words/s\n",
      "2018-03-25 00:44:04,831: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:04,833: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:04,836: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:04,845: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:04,846: INFO: EPOCH - 78 : training on 230239 raw words (185700 effective words) took 0.3s, 701796 effective words/s\n",
      "2018-03-25 00:44:05,089: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:05,091: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:05,097: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:05,102: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:05,103: INFO: EPOCH - 79 : training on 230239 raw words (185804 effective words) took 0.3s, 729472 effective words/s\n",
      "2018-03-25 00:44:05,379: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:05,381: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:05,395: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:05,399: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:05,401: INFO: EPOCH - 80 : training on 230239 raw words (185849 effective words) took 0.3s, 628869 effective words/s\n",
      "2018-03-25 00:44:05,766: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:05,768: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:05,769: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:05,778: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:05,780: INFO: EPOCH - 81 : training on 230239 raw words (185601 effective words) took 0.4s, 493937 effective words/s\n",
      "2018-03-25 00:44:06,032: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:06,035: INFO: worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-25 00:44:06,037: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:06,043: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:06,044: INFO: EPOCH - 82 : training on 230239 raw words (185813 effective words) took 0.3s, 711179 effective words/s\n",
      "2018-03-25 00:44:06,317: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:06,320: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:06,331: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:06,332: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:06,333: INFO: EPOCH - 83 : training on 230239 raw words (185864 effective words) took 0.3s, 648888 effective words/s\n",
      "2018-03-25 00:44:06,595: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:06,597: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:06,603: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:06,609: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:06,611: INFO: EPOCH - 84 : training on 230239 raw words (185750 effective words) took 0.3s, 679929 effective words/s\n",
      "2018-03-25 00:44:06,927: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:06,929: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:06,932: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:06,940: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:06,941: INFO: EPOCH - 85 : training on 230239 raw words (186026 effective words) took 0.3s, 580675 effective words/s\n",
      "2018-03-25 00:44:07,216: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:07,218: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:07,220: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:07,241: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:07,244: INFO: EPOCH - 86 : training on 230239 raw words (185871 effective words) took 0.3s, 620362 effective words/s\n",
      "2018-03-25 00:44:07,661: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:07,664: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:07,666: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:07,674: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:07,677: INFO: EPOCH - 87 : training on 230239 raw words (185935 effective words) took 0.4s, 479523 effective words/s\n",
      "2018-03-25 00:44:08,086: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:08,094: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:08,097: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:08,105: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:08,106: INFO: EPOCH - 88 : training on 230239 raw words (185851 effective words) took 0.4s, 440014 effective words/s\n",
      "2018-03-25 00:44:08,588: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:08,590: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:08,595: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:08,604: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:08,606: INFO: EPOCH - 89 : training on 230239 raw words (185884 effective words) took 0.5s, 376764 effective words/s\n",
      "2018-03-25 00:44:08,960: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:08,967: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:08,970: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:08,975: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:08,976: INFO: EPOCH - 90 : training on 230239 raw words (185911 effective words) took 0.4s, 517502 effective words/s\n",
      "2018-03-25 00:44:09,222: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:09,225: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:09,230: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:09,236: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:09,237: INFO: EPOCH - 91 : training on 230239 raw words (185845 effective words) took 0.3s, 718208 effective words/s\n",
      "2018-03-25 00:44:09,496: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:09,497: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:09,502: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:09,508: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:09,509: INFO: EPOCH - 92 : training on 230239 raw words (185571 effective words) took 0.3s, 689262 effective words/s\n",
      "2018-03-25 00:44:09,812: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:09,818: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:09,819: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:09,825: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:09,827: INFO: EPOCH - 93 : training on 230239 raw words (185769 effective words) took 0.3s, 589832 effective words/s\n",
      "2018-03-25 00:44:10,081: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:10,084: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:10,086: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:10,090: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:10,091: INFO: EPOCH - 94 : training on 230239 raw words (185866 effective words) took 0.3s, 721902 effective words/s\n",
      "2018-03-25 00:44:10,343: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:10,345: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:10,351: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:10,357: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:10,358: INFO: EPOCH - 95 : training on 230239 raw words (185953 effective words) took 0.3s, 704195 effective words/s\n",
      "2018-03-25 00:44:10,606: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:10,608: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:10,614: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:10,619: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:10,620: INFO: EPOCH - 96 : training on 230239 raw words (185789 effective words) took 0.3s, 714621 effective words/s\n",
      "2018-03-25 00:44:10,873: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:10,876: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:10,879: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:10,885: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:10,887: INFO: EPOCH - 97 : training on 230239 raw words (185736 effective words) took 0.3s, 705484 effective words/s\n",
      "2018-03-25 00:44:11,179: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:11,181: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:11,187: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:11,192: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:11,193: INFO: EPOCH - 98 : training on 230239 raw words (185919 effective words) took 0.3s, 611912 effective words/s\n",
      "2018-03-25 00:44:11,461: INFO: worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-25 00:44:11,463: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:11,472: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:11,476: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:11,477: INFO: EPOCH - 99 : training on 230239 raw words (185870 effective words) took 0.3s, 659932 effective words/s\n",
      "2018-03-25 00:44:11,723: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:11,724: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:11,728: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:11,735: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:11,736: INFO: EPOCH - 100 : training on 230239 raw words (185823 effective words) took 0.3s, 728084 effective words/s\n",
      "2018-03-25 00:44:12,014: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:12,018: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:12,021: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:12,029: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:12,030: INFO: EPOCH - 101 : training on 230239 raw words (185762 effective words) took 0.3s, 637128 effective words/s\n",
      "2018-03-25 00:44:12,361: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:12,363: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:12,373: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:12,374: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:12,376: INFO: EPOCH - 102 : training on 230239 raw words (185809 effective words) took 0.3s, 543306 effective words/s\n",
      "2018-03-25 00:44:12,627: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:12,630: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:12,631: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:12,639: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:12,640: INFO: EPOCH - 103 : training on 230239 raw words (185976 effective words) took 0.3s, 710802 effective words/s\n",
      "2018-03-25 00:44:12,901: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:12,902: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:12,912: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:12,915: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:12,916: INFO: EPOCH - 104 : training on 230239 raw words (185766 effective words) took 0.3s, 680217 effective words/s\n",
      "2018-03-25 00:44:13,171: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:13,173: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:13,179: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:13,186: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:13,187: INFO: EPOCH - 105 : training on 230239 raw words (185711 effective words) took 0.3s, 691144 effective words/s\n",
      "2018-03-25 00:44:13,530: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:13,538: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:13,548: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:13,556: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:13,557: INFO: EPOCH - 106 : training on 230239 raw words (185866 effective words) took 0.4s, 506766 effective words/s\n",
      "2018-03-25 00:44:13,831: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:13,833: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:13,838: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:13,844: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:13,845: INFO: EPOCH - 107 : training on 230239 raw words (185891 effective words) took 0.3s, 650745 effective words/s\n",
      "2018-03-25 00:44:14,107: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:14,109: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:14,118: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:14,121: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:14,122: INFO: EPOCH - 108 : training on 230239 raw words (186033 effective words) took 0.3s, 722670 effective words/s\n",
      "2018-03-25 00:44:14,380: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:14,384: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:14,387: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:14,398: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:14,399: INFO: EPOCH - 109 : training on 230239 raw words (185924 effective words) took 0.3s, 676270 effective words/s\n",
      "2018-03-25 00:44:14,650: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:14,657: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:14,660: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:14,663: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:14,664: INFO: EPOCH - 110 : training on 230239 raw words (185799 effective words) took 0.3s, 712167 effective words/s\n",
      "2018-03-25 00:44:14,961: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:14,963: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:14,970: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:14,974: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:14,975: INFO: EPOCH - 111 : training on 230239 raw words (185915 effective words) took 0.3s, 601499 effective words/s\n",
      "2018-03-25 00:44:15,235: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:15,237: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:15,242: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:15,250: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:15,252: INFO: EPOCH - 112 : training on 230239 raw words (185971 effective words) took 0.3s, 679417 effective words/s\n",
      "2018-03-25 00:44:15,509: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:15,512: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:15,518: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:15,523: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:15,525: INFO: EPOCH - 113 : training on 230239 raw words (185886 effective words) took 0.3s, 688107 effective words/s\n",
      "2018-03-25 00:44:15,777: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:15,783: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:15,785: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:15,790: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:15,792: INFO: EPOCH - 114 : training on 230239 raw words (185941 effective words) took 0.3s, 706500 effective words/s\n",
      "2018-03-25 00:44:16,112: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:16,117: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:16,121: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:16,129: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:16,130: INFO: EPOCH - 115 : training on 230239 raw words (185866 effective words) took 0.3s, 553219 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-25 00:44:16,391: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:16,393: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:16,398: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:16,404: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:16,405: INFO: EPOCH - 116 : training on 230239 raw words (185759 effective words) took 0.3s, 681464 effective words/s\n",
      "2018-03-25 00:44:16,657: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:16,661: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:16,663: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:16,669: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:16,670: INFO: EPOCH - 117 : training on 230239 raw words (185712 effective words) took 0.3s, 707606 effective words/s\n",
      "2018-03-25 00:44:16,921: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:16,928: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:16,929: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:16,934: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:16,935: INFO: EPOCH - 118 : training on 230239 raw words (185925 effective words) took 0.3s, 708506 effective words/s\n",
      "2018-03-25 00:44:17,246: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:17,253: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:17,258: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:17,263: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:17,264: INFO: EPOCH - 119 : training on 230239 raw words (185861 effective words) took 0.3s, 568884 effective words/s\n",
      "2018-03-25 00:44:17,540: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:17,543: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:17,545: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:17,554: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:17,556: INFO: EPOCH - 120 : training on 230239 raw words (185912 effective words) took 0.3s, 642527 effective words/s\n",
      "2018-03-25 00:44:17,829: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:17,836: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:17,838: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:17,847: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:17,848: INFO: EPOCH - 121 : training on 230239 raw words (185776 effective words) took 0.3s, 639940 effective words/s\n",
      "2018-03-25 00:44:18,102: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:18,110: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:18,112: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:18,120: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:18,121: INFO: EPOCH - 122 : training on 230239 raw words (185823 effective words) took 0.3s, 687971 effective words/s\n",
      "2018-03-25 00:44:18,420: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:18,428: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:18,432: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:18,434: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:18,435: INFO: EPOCH - 123 : training on 230239 raw words (186001 effective words) took 0.3s, 599142 effective words/s\n",
      "2018-03-25 00:44:18,697: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:18,699: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:18,710: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:18,711: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:18,713: INFO: EPOCH - 124 : training on 230239 raw words (186024 effective words) took 0.3s, 678491 effective words/s\n",
      "2018-03-25 00:44:18,963: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:18,970: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:18,975: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:18,977: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:18,979: INFO: EPOCH - 125 : training on 230239 raw words (185943 effective words) took 0.3s, 706391 effective words/s\n",
      "2018-03-25 00:44:19,236: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:19,245: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:19,247: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:19,251: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:19,252: INFO: EPOCH - 126 : training on 230239 raw words (185890 effective words) took 0.3s, 686631 effective words/s\n",
      "2018-03-25 00:44:19,570: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:19,572: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:19,580: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:19,583: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:19,585: INFO: EPOCH - 127 : training on 230239 raw words (185834 effective words) took 0.3s, 566626 effective words/s\n",
      "2018-03-25 00:44:19,882: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:19,887: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:19,889: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:19,899: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:19,900: INFO: EPOCH - 128 : training on 230239 raw words (185899 effective words) took 0.3s, 596244 effective words/s\n",
      "2018-03-25 00:44:20,165: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:20,167: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:20,173: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:20,178: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:20,180: INFO: EPOCH - 129 : training on 230239 raw words (185967 effective words) took 0.3s, 678080 effective words/s\n",
      "2018-03-25 00:44:20,429: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:20,435: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:20,436: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:20,442: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:20,444: INFO: EPOCH - 130 : training on 230239 raw words (185877 effective words) took 0.2s, 751558 effective words/s\n",
      "2018-03-25 00:44:20,698: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:20,702: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:20,705: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:20,713: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:20,715: INFO: EPOCH - 131 : training on 230239 raw words (186009 effective words) took 0.3s, 692830 effective words/s\n",
      "2018-03-25 00:44:21,022: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:21,025: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:21,035: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:21,037: INFO: worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-25 00:44:21,038: INFO: EPOCH - 132 : training on 230239 raw words (185822 effective words) took 0.3s, 579226 effective words/s\n",
      "2018-03-25 00:44:21,301: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:21,305: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:21,312: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:21,319: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:21,320: INFO: EPOCH - 133 : training on 230239 raw words (185867 effective words) took 0.3s, 663974 effective words/s\n",
      "2018-03-25 00:44:21,570: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:21,580: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:21,583: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:21,590: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:21,591: INFO: EPOCH - 134 : training on 230239 raw words (185842 effective words) took 0.3s, 692703 effective words/s\n",
      "2018-03-25 00:44:21,847: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:21,849: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:21,855: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:21,867: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:21,869: INFO: EPOCH - 135 : training on 230239 raw words (185836 effective words) took 0.3s, 674985 effective words/s\n",
      "2018-03-25 00:44:22,181: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:22,190: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:22,191: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:22,196: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:22,198: INFO: EPOCH - 136 : training on 230239 raw words (185857 effective words) took 0.3s, 569885 effective words/s\n",
      "2018-03-25 00:44:22,473: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:22,478: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:22,479: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:22,486: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:22,487: INFO: EPOCH - 137 : training on 230239 raw words (185729 effective words) took 0.3s, 647637 effective words/s\n",
      "2018-03-25 00:44:22,785: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:22,795: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:22,808: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:22,812: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:22,814: INFO: EPOCH - 138 : training on 230239 raw words (185686 effective words) took 0.3s, 573474 effective words/s\n",
      "2018-03-25 00:44:23,175: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:23,176: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:23,185: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:23,186: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:23,188: INFO: EPOCH - 139 : training on 230239 raw words (185972 effective words) took 0.4s, 508641 effective words/s\n",
      "2018-03-25 00:44:23,494: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:23,499: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:23,506: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:23,508: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:23,509: INFO: EPOCH - 140 : training on 230239 raw words (185753 effective words) took 0.3s, 582556 effective words/s\n",
      "2018-03-25 00:44:23,848: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:23,864: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:23,872: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:23,879: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:23,881: INFO: EPOCH - 141 : training on 230239 raw words (185911 effective words) took 0.4s, 504749 effective words/s\n",
      "2018-03-25 00:44:24,204: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:24,206: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:24,209: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:24,218: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:24,219: INFO: EPOCH - 142 : training on 230239 raw words (185768 effective words) took 0.3s, 559293 effective words/s\n",
      "2018-03-25 00:44:24,485: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:24,489: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:24,495: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:24,501: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:24,503: INFO: EPOCH - 143 : training on 230239 raw words (185824 effective words) took 0.3s, 661710 effective words/s\n",
      "2018-03-25 00:44:24,810: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:24,819: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:24,820: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:24,824: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:24,825: INFO: EPOCH - 144 : training on 230239 raw words (186083 effective words) took 0.3s, 581189 effective words/s\n",
      "2018-03-25 00:44:25,136: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:25,138: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:25,145: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:25,148: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:25,150: INFO: EPOCH - 145 : training on 230239 raw words (186031 effective words) took 0.3s, 584820 effective words/s\n",
      "2018-03-25 00:44:25,456: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:25,458: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:25,464: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:25,474: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:25,475: INFO: EPOCH - 146 : training on 230239 raw words (185844 effective words) took 0.3s, 574680 effective words/s\n",
      "2018-03-25 00:44:25,748: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:25,754: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:25,758: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:25,762: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:25,763: INFO: EPOCH - 147 : training on 230239 raw words (185760 effective words) took 0.3s, 651870 effective words/s\n",
      "2018-03-25 00:44:26,072: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:26,075: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:26,088: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:26,093: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:26,095: INFO: EPOCH - 148 : training on 230239 raw words (186115 effective words) took 0.3s, 566197 effective words/s\n",
      "2018-03-25 00:44:26,417: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:26,421: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:26,426: INFO: worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-25 00:44:26,433: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:26,435: INFO: EPOCH - 149 : training on 230239 raw words (185846 effective words) took 0.3s, 551173 effective words/s\n",
      "2018-03-25 00:44:26,690: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:26,697: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:26,704: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:26,710: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:26,711: INFO: EPOCH - 150 : training on 230239 raw words (185789 effective words) took 0.3s, 685693 effective words/s\n",
      "2018-03-25 00:44:26,963: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:26,965: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:26,973: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:26,978: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:26,979: INFO: EPOCH - 151 : training on 230239 raw words (185898 effective words) took 0.3s, 699789 effective words/s\n",
      "2018-03-25 00:44:27,228: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:27,230: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:27,234: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:27,239: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:27,240: INFO: EPOCH - 152 : training on 230239 raw words (185677 effective words) took 0.3s, 719375 effective words/s\n",
      "2018-03-25 00:44:27,542: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:27,550: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:27,552: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:27,558: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:27,559: INFO: EPOCH - 153 : training on 230239 raw words (185899 effective words) took 0.3s, 587483 effective words/s\n",
      "2018-03-25 00:44:27,812: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:27,814: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:27,817: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:27,826: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:27,827: INFO: EPOCH - 154 : training on 230239 raw words (186057 effective words) took 0.3s, 699739 effective words/s\n",
      "2018-03-25 00:44:28,079: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:28,084: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:28,087: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:28,094: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:28,095: INFO: EPOCH - 155 : training on 230239 raw words (185791 effective words) took 0.3s, 699701 effective words/s\n",
      "2018-03-25 00:44:28,425: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:28,428: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:28,438: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:28,442: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:28,444: INFO: EPOCH - 156 : training on 230239 raw words (185837 effective words) took 0.3s, 538224 effective words/s\n",
      "2018-03-25 00:44:28,699: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:28,702: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:28,708: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:28,717: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:28,719: INFO: EPOCH - 157 : training on 230239 raw words (185885 effective words) took 0.3s, 687928 effective words/s\n",
      "2018-03-25 00:44:29,068: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:29,071: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:29,073: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:29,080: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:29,082: INFO: EPOCH - 158 : training on 230239 raw words (185862 effective words) took 0.4s, 514696 effective words/s\n",
      "2018-03-25 00:44:29,448: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:29,450: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:29,453: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:29,461: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:29,463: INFO: EPOCH - 159 : training on 230239 raw words (185950 effective words) took 0.4s, 494268 effective words/s\n",
      "2018-03-25 00:44:29,763: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:29,769: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:29,772: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:29,779: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:29,781: INFO: EPOCH - 160 : training on 230239 raw words (185782 effective words) took 0.3s, 591636 effective words/s\n",
      "2018-03-25 00:44:30,081: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:30,083: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:30,086: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:30,095: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:30,096: INFO: EPOCH - 161 : training on 230239 raw words (185786 effective words) took 0.3s, 598100 effective words/s\n",
      "2018-03-25 00:44:30,401: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:30,403: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:30,407: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:30,413: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:30,414: INFO: EPOCH - 162 : training on 230239 raw words (185735 effective words) took 0.3s, 588909 effective words/s\n",
      "2018-03-25 00:44:30,669: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:30,672: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:30,678: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:30,687: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:30,688: INFO: EPOCH - 163 : training on 230239 raw words (185895 effective words) took 0.3s, 684517 effective words/s\n",
      "2018-03-25 00:44:30,944: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:30,947: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:30,950: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:30,956: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:30,957: INFO: EPOCH - 164 : training on 230239 raw words (185750 effective words) took 0.3s, 700182 effective words/s\n",
      "2018-03-25 00:44:31,221: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:31,223: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:31,233: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:31,235: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:31,236: INFO: EPOCH - 165 : training on 230239 raw words (185768 effective words) took 0.3s, 670795 effective words/s\n",
      "2018-03-25 00:44:31,544: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:31,546: INFO: worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-25 00:44:31,548: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:31,557: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:31,558: INFO: EPOCH - 166 : training on 230239 raw words (186030 effective words) took 0.3s, 582848 effective words/s\n",
      "2018-03-25 00:44:31,815: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:31,817: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:31,822: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:31,826: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:31,828: INFO: EPOCH - 167 : training on 230239 raw words (185864 effective words) took 0.3s, 697659 effective words/s\n",
      "2018-03-25 00:44:32,067: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:32,068: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:32,077: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:32,079: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:32,080: INFO: EPOCH - 168 : training on 230239 raw words (185574 effective words) took 0.3s, 742215 effective words/s\n",
      "2018-03-25 00:44:32,335: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:32,337: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:32,343: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:32,348: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:32,349: INFO: EPOCH - 169 : training on 230239 raw words (185850 effective words) took 0.3s, 697764 effective words/s\n",
      "2018-03-25 00:44:32,640: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:32,642: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:32,644: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:32,652: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:32,654: INFO: EPOCH - 170 : training on 230239 raw words (185509 effective words) took 0.3s, 613904 effective words/s\n",
      "2018-03-25 00:44:32,937: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:32,939: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:32,942: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:32,951: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:32,952: INFO: EPOCH - 171 : training on 230239 raw words (186019 effective words) took 0.3s, 629555 effective words/s\n",
      "2018-03-25 00:44:33,203: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:33,205: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:33,209: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:33,217: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:33,219: INFO: EPOCH - 172 : training on 230239 raw words (185645 effective words) took 0.3s, 706276 effective words/s\n",
      "2018-03-25 00:44:33,468: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:33,470: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:33,475: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:33,481: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:33,482: INFO: EPOCH - 173 : training on 230239 raw words (185648 effective words) took 0.3s, 721150 effective words/s\n",
      "2018-03-25 00:44:33,815: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:33,817: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:33,829: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:33,832: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:33,834: INFO: EPOCH - 174 : training on 230239 raw words (185811 effective words) took 0.3s, 531397 effective words/s\n",
      "2018-03-25 00:44:34,116: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:34,119: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:34,128: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:34,135: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:34,137: INFO: EPOCH - 175 : training on 230239 raw words (186002 effective words) took 0.3s, 631925 effective words/s\n",
      "2018-03-25 00:44:34,401: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:34,403: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:34,408: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:34,413: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:34,414: INFO: EPOCH - 176 : training on 230239 raw words (185563 effective words) took 0.3s, 678732 effective words/s\n",
      "2018-03-25 00:44:34,666: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:34,667: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:34,673: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:34,677: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:34,678: INFO: EPOCH - 177 : training on 230239 raw words (185960 effective words) took 0.3s, 711684 effective words/s\n",
      "2018-03-25 00:44:34,947: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:34,949: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:34,955: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:34,959: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:34,960: INFO: EPOCH - 178 : training on 230239 raw words (185949 effective words) took 0.3s, 665882 effective words/s\n",
      "2018-03-25 00:44:35,262: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:35,264: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:35,273: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:35,275: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:35,276: INFO: EPOCH - 179 : training on 230239 raw words (185741 effective words) took 0.3s, 591259 effective words/s\n",
      "2018-03-25 00:44:35,534: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:35,536: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:35,544: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:35,546: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:35,547: INFO: EPOCH - 180 : training on 230239 raw words (185921 effective words) took 0.3s, 693605 effective words/s\n",
      "2018-03-25 00:44:35,795: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:35,796: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:35,801: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:35,805: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:35,806: INFO: EPOCH - 181 : training on 230239 raw words (185692 effective words) took 0.3s, 727031 effective words/s\n",
      "2018-03-25 00:44:36,054: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:36,057: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:36,059: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:36,067: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:36,069: INFO: EPOCH - 182 : training on 230239 raw words (185998 effective words) took 0.3s, 716627 effective words/s\n",
      "2018-03-25 00:44:36,392: INFO: worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-25 00:44:36,394: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:36,403: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:36,404: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:36,406: INFO: EPOCH - 183 : training on 230239 raw words (185708 effective words) took 0.3s, 553702 effective words/s\n",
      "2018-03-25 00:44:36,654: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:36,658: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:36,665: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:36,667: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:36,668: INFO: EPOCH - 184 : training on 230239 raw words (185900 effective words) took 0.3s, 717047 effective words/s\n",
      "2018-03-25 00:44:36,911: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:36,914: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:36,922: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:36,931: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:36,932: INFO: EPOCH - 185 : training on 230239 raw words (186102 effective words) took 0.3s, 712933 effective words/s\n",
      "2018-03-25 00:44:37,192: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:37,194: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:37,200: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:37,206: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:37,207: INFO: EPOCH - 186 : training on 230239 raw words (185958 effective words) took 0.3s, 682146 effective words/s\n",
      "2018-03-25 00:44:37,507: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:37,508: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:37,513: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:37,519: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:37,521: INFO: EPOCH - 187 : training on 230239 raw words (185763 effective words) took 0.3s, 599123 effective words/s\n",
      "2018-03-25 00:44:37,761: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:37,763: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:37,768: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:37,773: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:37,774: INFO: EPOCH - 188 : training on 230239 raw words (185960 effective words) took 0.3s, 741348 effective words/s\n",
      "2018-03-25 00:44:38,018: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:38,020: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:38,026: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:38,032: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:38,033: INFO: EPOCH - 189 : training on 230239 raw words (185839 effective words) took 0.3s, 723891 effective words/s\n",
      "2018-03-25 00:44:38,272: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:38,275: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:38,281: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:38,289: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:38,291: INFO: EPOCH - 190 : training on 230239 raw words (185958 effective words) took 0.3s, 730688 effective words/s\n",
      "2018-03-25 00:44:38,588: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:38,590: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:38,592: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:38,601: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:38,602: INFO: EPOCH - 191 : training on 230239 raw words (185949 effective words) took 0.3s, 602091 effective words/s\n",
      "2018-03-25 00:44:38,847: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:38,849: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:38,851: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:38,859: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:38,861: INFO: EPOCH - 192 : training on 230239 raw words (186006 effective words) took 0.3s, 726915 effective words/s\n",
      "2018-03-25 00:44:39,120: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:39,121: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:39,125: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:39,133: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:39,134: INFO: EPOCH - 193 : training on 230239 raw words (185906 effective words) took 0.3s, 686595 effective words/s\n",
      "2018-03-25 00:44:39,387: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:39,389: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:39,398: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:39,399: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:39,401: INFO: EPOCH - 194 : training on 230239 raw words (185949 effective words) took 0.3s, 702933 effective words/s\n",
      "2018-03-25 00:44:39,735: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:39,738: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:39,749: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:39,751: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:39,752: INFO: EPOCH - 195 : training on 230239 raw words (185952 effective words) took 0.3s, 532917 effective words/s\n",
      "2018-03-25 00:44:40,054: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:40,056: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:40,066: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:40,070: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:40,071: INFO: EPOCH - 196 : training on 230239 raw words (186067 effective words) took 0.3s, 590139 effective words/s\n",
      "2018-03-25 00:44:40,375: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:40,377: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:40,382: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:40,389: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:40,391: INFO: EPOCH - 197 : training on 230239 raw words (186020 effective words) took 0.3s, 590505 effective words/s\n",
      "2018-03-25 00:44:40,659: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:40,662: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:40,669: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:40,674: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:40,675: INFO: EPOCH - 198 : training on 230239 raw words (185819 effective words) took 0.3s, 660516 effective words/s\n",
      "2018-03-25 00:44:40,974: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:40,976: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:40,979: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:40,986: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:40,987: INFO: EPOCH - 199 : training on 230239 raw words (185795 effective words) took 0.3s, 600490 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-25 00:44:41,229: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-25 00:44:41,230: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-25 00:44:41,234: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-25 00:44:41,244: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-25 00:44:41,246: INFO: EPOCH - 200 : training on 230239 raw words (185882 effective words) took 0.3s, 726415 effective words/s\n",
      "2018-03-25 00:44:41,247: INFO: training on a 46047800 raw words (37168939 effective words) took 62.7s, 593212 effective words/s\n",
      "2018-03-25 00:44:41,249: INFO: saving Word2Vec object under model/word.model, separately None\n",
      "2018-03-25 00:44:41,250: INFO: not storing attribute vectors_norm\n",
      "2018-03-25 00:44:41,252: INFO: not storing attribute cum_table\n",
      "2018-03-25 00:44:41,297: INFO: saved model/word.model\n",
      "2018-03-25 00:44:41,299: INFO: storing 13319x4 projection weights into model/word.vector\n",
      "2018-03-25 00:44:41,419: INFO: loading projection weights from model/word.vector\n",
      "2018-03-25 00:44:41,551: INFO: loaded (13319, 4) matrix from model/word.vector\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "feature_size = 4\n",
    "\n",
    "'''\n",
    "word2vec\n",
    "dimensionï¼šfeature_sizeï¼ŒIterationsï¼š200\n",
    "'''\n",
    "def word_to_vec(file_in, file_out1, file_out2):\n",
    "\tlogging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s')\n",
    "\tlogging.root.setLevel(level=logging.INFO)\n",
    "\tmodel = Word2Vec(LineSentence(file_in), size=feature_size, window=5, min_count=1, workers=multiprocessing.cpu_count(), iter=200)\n",
    "\tmodel.save(file_out1)\n",
    "\tmodel.wv.save_word2vec_format(file_out2, binary=False)\n",
    "\n",
    "def read_sentence(file):\n",
    "\tres = []\n",
    "\twith open(file, 'r', encoding='utf-8') as f:\n",
    "\t\tlines = f.readlines()\n",
    "\tfor i in range(len(lines)):\n",
    "\t\tline = lines[i].split()\n",
    "\t\tres.append(line)\n",
    "\treturn res\n",
    "\n",
    "def main():\n",
    "\ttrain_vector = True\t\t# True = Train, False = Take a trained model\n",
    "\n",
    "\tif train_vector:\n",
    "\t\tword_to_vec('data/sentence.txt', 'model/word.model', 'model/word.vector')\n",
    "\t\n",
    "\t# tale trained model\n",
    "\tword_vectors = KeyedVectors.load_word2vec_format('model/word.vector', binary=False)\n",
    "\n",
    "\tfeature = []\t\t# Feature vector of all sentences\n",
    "\tsentence = read_sentence('data/sentence.txt')\n",
    "\tfor i in range(len(sentence)):\n",
    "\t\tfea = np.zeros(feature_size)\t\t# Feature vector of a specific sentence\n",
    "\t\tfor j in range(len(sentence[i])):\n",
    "\t\t\tv = word_vectors[sentence[i][j]]\t\t# word vector in the sentence\n",
    "\t\t\tfea += v\n",
    "\t\tfea = fea / len(sentence[i])\t\t# feature vector of the sentence, weighted average of the word vectors\n",
    "\t\tfeature.append(fea)\n",
    "\n",
    "\t# Add feature vector into the feature.txt file\n",
    "\twith open('data/feature.txt', 'w', encoding='utf-8') as f:\n",
    "\t\tfor i in range(len(feature)):\n",
    "\t\t\tfor j in range(feature[i].shape[0]):\n",
    "\t\t\t\tf.write(str(feature[i][j]))\n",
    "\t\t\t\tif j != feature[i].shape[0]-1:\n",
    "\t\t\t\t\tf.write('\\t')\n",
    "\t\t\tf.write('\\n')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main_word2vec.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading feature information...\n",
      "\n",
      "reading label information...\n",
      "\n",
      "52205.2\n",
      "44056.9\n",
      "42801.9\n",
      "42327.2\n",
      "42073.9\n",
      "41916.0\n",
      "41805.3\n",
      "41722.5\n",
      "41660.9\n",
      "41614.4\n",
      "41577.8\n",
      "41548.0\n",
      "41523.3\n",
      "41502.3\n",
      "41484.3\n",
      "41468.7\n",
      "41455.0\n",
      "41442.9\n",
      "41432.0\n",
      "41422.1\n",
      "41413.2\n",
      "41405.0\n",
      "41397.5\n",
      "41390.5\n",
      "41384.2\n",
      "41378.2\n",
      "41372.7\n",
      "41367.6\n",
      "41362.8\n",
      "41358.3\n",
      "41354.1\n",
      "41350.1\n",
      "41346.4\n",
      "41342.8\n",
      "41339.5\n",
      "41336.3\n",
      "41333.3\n",
      "41330.4\n",
      "41327.7\n",
      "41325.0\n",
      "41322.5\n",
      "41320.0\n",
      "41317.7\n",
      "41315.4\n",
      "41313.2\n",
      "41311.0\n",
      "41308.9\n",
      "41306.9\n",
      "41304.9\n",
      "41303.0\n",
      "41301.1\n",
      "41299.3\n",
      "41297.5\n",
      "41295.9\n",
      "41294.2\n",
      "41292.6\n",
      "41291.0\n",
      "41289.5\n",
      "41288.0\n",
      "41286.6\n",
      "41285.2\n",
      "41283.8\n",
      "41282.4\n",
      "41281.1\n",
      "41279.8\n",
      "41278.5\n",
      "41277.2\n",
      "41276.0\n",
      "41274.7\n",
      "41273.5\n",
      "41272.2\n",
      "41271.0\n",
      "41269.8\n",
      "41268.6\n",
      "41267.4\n",
      "41266.2\n",
      "41265.0\n",
      "41263.9\n",
      "41262.7\n",
      "41261.5\n",
      "Accuracy:  0.1978963770938839\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.07      0.25      0.11       122\n",
      "          1       0.09      0.17      0.12       228\n",
      "          2       0.03      0.24      0.05        37\n",
      "          3       0.13      0.18      0.15       309\n",
      "          4       0.24      0.18      0.21       577\n",
      "          5       0.54      0.21      0.30      1294\n",
      "\n",
      "avg / total       0.35      0.20      0.23      2567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Read features\n",
    "def read_feature(file):\n",
    "  print(\"reading feature information...\\n\")\n",
    "  res = []\n",
    "  with open(file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "  for line in lines:\n",
    "    line = line.split()\n",
    "    for i in range(len(line)):\n",
    "      line[i] = float(line[i])\n",
    "    res.append(line)\n",
    "  return np.array(res)\n",
    "\n",
    "# Read labels\n",
    "def read_label(file):\n",
    "  print(\"reading label information...\\n\")\n",
    "  res = []\n",
    "  with open(file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "  for line in lines:\n",
    "    line = int(line.strip())\n",
    "    res.append(line)\n",
    "  return np.array(res)\n",
    "\n",
    "def addLayer(inputData, inSize, outSize, activity_function = None):  \n",
    "    Weights = tf.Variable(tf.random_normal([inSize, outSize]))   \n",
    "    basis = tf.Variable(tf.random_uniform([1,outSize], -1, 1))    \n",
    "    weights_plus_b = tf.matmul(inputData, Weights) + basis  \n",
    "    #Wx_plus_b = tf.nn.dropout(weights_plus_b, keep_prob = 0.8)     # To prevent overfitting\n",
    "\n",
    "    if activity_function is None:  \n",
    "        ans = weights_plus_b  \n",
    "    else:  \n",
    "        ans = activity_function(weights_plus_b)\n",
    "    return ans  \n",
    "\n",
    "def net(x_data, y_data, x_test, y_test):\n",
    "    is_train = True\n",
    "\n",
    "\n",
    "    insize = x_data.shape[1]\n",
    "    outsize = 8\n",
    "    xs = tf.placeholder(tf.float32,[None, insize]) \n",
    "    ys = tf.placeholder(tf.float32,[None, outsize]) \n",
    "    keep_prob = tf.placeholder(tf.float32)  \n",
    "      \n",
    "    l1 = addLayer(xs, insize, 40,activity_function=None)  \n",
    "    l2 = addLayer(l1, 40, 20,activity_function=tf.nn.sigmoid)  \n",
    "    l3 = addLayer(l2, 20, 10,activity_function=tf.nn.softmax)  \n",
    "    l4 = addLayer(l3, 10, outsize,activity_function=tf.nn.softmax)\n",
    "\n",
    "\n",
    "    y = l4\n",
    "    #loss = tf.reduce_sum(tf.reduce_sum(tf.square((ys-l4)),reduction_indices = [1]))  \n",
    "    #loss = -tf.reduce_mean(ys * tf.log(l3))\n",
    "    #loss = tf.reduce_sum(tf.square((ys-y)))\n",
    "    loss = -tf.reduce_sum(ys * tf.log(y))\n",
    "    #loss = tf.reduce_sum(-tf.reduce_sum(ys * tf.log(y),reduction_indices=[1]))  # loss  \n",
    "    train =  tf.train.GradientDescentOptimizer(0.00001).minimize(loss) \n",
    "\n",
    "    # Turn 1 dimensional label vectors to 14 dimensional vectors which has only one element = 1\n",
    "    new_ydata = []\n",
    "    for i in range(y_data.shape[0]):\n",
    "      new_ydata.append([0]*outsize)\n",
    "      new_ydata[i][y_data[i]] = 1\n",
    "      # print(new_ydata[i])\n",
    "    new_ydata = np.array(new_ydata)\n",
    "        \n",
    "    saver=tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        if is_train: \n",
    "            run_step = 4000\n",
    "            for i in range(run_step):  \n",
    "                sess.run(train,feed_dict={xs:x_data,ys:new_ydata})  \n",
    "                if i%50 == 0:  \n",
    "                    print(sess.run(loss,feed_dict={xs:x_data,ys:new_ydata}))\n",
    "            # save the model\n",
    "            saver=tf.train.Saver(max_to_keep=1)\n",
    "            saver.save(sess,'model/net.ckpt')\n",
    "        else:     # take a trained model\n",
    "            saver.restore(sess, 'model/net.ckpt')\n",
    "            print(\"save success!\")\n",
    "\n",
    "        # Prediction\n",
    "        res = sess.run(fetches=y, feed_dict={xs: x_test})\n",
    "        new_res = []\n",
    "        for ele in res:\n",
    "            mmax = -1111\n",
    "            index = -1\n",
    "            for i in range(outsize):\n",
    "                if ele[i] > mmax:\n",
    "                    index, mmax  = i, ele[i]\n",
    "            new_res.append(index)\n",
    "        #print(new_res)\n",
    "        new_res = np.array(new_res)\n",
    "        counter = 0\n",
    "        for i in range(len(new_res)):\n",
    "          if(y_test[i] == new_res[i]):\n",
    "            counter += 1\n",
    "        print(\"Accuracy: \", counter/len(new_res))\n",
    "        print(classification_report(new_res, y_test))\n",
    "\n",
    "def main():\n",
    "  feature = read_feature('data/feature.txt')\n",
    "  label = read_label('data/label.txt')\n",
    "\n",
    "  x_train , x_test , y_train , y_test = train_test_split(feature, label, test_size = 0.1,random_state=0)\n",
    "  net(x_train, y_train, x_test, y_test)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "3.5121\n",
      "3.49469\n",
      "3.47797\n",
      "3.46151\n",
      "3.44524\n",
      "3.42944\n",
      "3.41388\n",
      "3.39861\n",
      "3.38354\n",
      "3.36865\n",
      "3.35384\n",
      "3.33911\n",
      "3.32435\n",
      "3.30993\n",
      "3.29582\n",
      "3.28172\n",
      "3.26782\n",
      "3.2541\n",
      "3.24049\n",
      "3.22707\n",
      "Accuracy:  0.162835995325\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import data_helpers\n",
    "#from text_cnn import TextCNN\n",
    "from tensorflow.contrib import learn\n",
    "from sklearn.metrics import accuracy_score  \n",
    "\n",
    "\n",
    "def read_feature(file):\n",
    "  print(\"reading feature information...\\n\")\n",
    "  res = []\n",
    "  with open(file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "  for line in lines:\n",
    "    line = line.split()\n",
    "    for i in range(len(line)):\n",
    "      line[i] = float(line[i])\n",
    "    res.append(line)\n",
    "  return np.array(res)\n",
    "\n",
    "def read_label(file):\n",
    "  print(\"reading label information...\\n\")\n",
    "  res = []\n",
    "  with open(file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "  for line in lines:\n",
    "    line = int(line.strip())\n",
    "    res.append(line)\n",
    "  return np.array(res)\n",
    "\n",
    "def addLayer(inputData, inSize, outSize, activity_function = None):  \n",
    "    Weights = tf.Variable(tf.random_normal([inSize, outSize]))   \n",
    "    basis = tf.Variable(tf.random_uniform([1,outSize], -1, 1))    \n",
    "    weights_plus_b = tf.matmul(inputData, Weights) + basis  \n",
    "    Wx_plus_b = tf.nn.dropout(weights_plus_b, keep_prob = 1)     # To prevent overfitting\n",
    "\n",
    "    if activity_function is None:  \n",
    "        ans = weights_plus_b  \n",
    "    else:  \n",
    "        ans = activity_function(weights_plus_b)\n",
    "    return ans  \n",
    "\n",
    "def net(x_data, y_data, x_test, y_test):\n",
    "    is_train = True\n",
    "\n",
    "\n",
    "    insize = x_data.shape[1]\n",
    "    outsize = 6\n",
    "    xs = tf.placeholder(tf.float32,[None, insize])   \n",
    "    ys = tf.placeholder(tf.float32,[None, outsize])  \n",
    "    keep_prob = tf.placeholder(tf.float32)  \n",
    "      \n",
    "    l1 = addLayer(xs, insize, 40,activity_function=tf.nn.sigmoid)  \n",
    "    l2 = addLayer(l1, 40, 20,activity_function=tf.nn.sigmoid)  \n",
    "    l3 = addLayer(l2, 20, 10,activity_function=tf.nn.sigmoid)  \n",
    "    l4 = addLayer(l3, 10, outsize,activity_function=tf.nn.softmax)\n",
    "    #l5 = addLayer(l4, 10, outsize,activity_function=tf.nn.softmax)\n",
    "\n",
    "\n",
    "    y = l4\n",
    "    #loss = tf.reduce_sum(tf.reduce_sum(tf.square((ys-l4)),reduction_indices = [1]))  \n",
    "    #loss = -tf.reduce_mean(ys * tf.log(l3))\n",
    "    #loss = tf.reduce_sum(tf.square((ys-y)))\n",
    "    #oss = -tf.reduce_sum(ys * tf.log(y))\n",
    "    loss = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(y),reduction_indices=[1]))  # loss  \n",
    "    train =  tf.train.GradientDescentOptimizer(0.0001).minimize(loss) \n",
    "\n",
    "    new_ydata = []\n",
    "    for i in range(y_data.shape[0]):\n",
    "      new_ydata.append([0]*outsize)\n",
    "      new_ydata[i][y_data[i]] = 1\n",
    "      # print(new_ydata[i])\n",
    "    new_ydata = np.array(new_ydata)\n",
    "        \n",
    "    saver=tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        if is_train: \n",
    "            run_step = 1000\n",
    "            for i in range(run_step):  \n",
    "                sess.run(train,feed_dict={xs:x_data,ys:new_ydata})  \n",
    "                if i%50 == 0:  \n",
    "                    print(sess.run(loss,feed_dict={xs:x_data,ys:new_ydata}))\n",
    "            # save the model\n",
    "            saver=tf.train.Saver(max_to_keep=1)\n",
    "            saver.save(sess,'model/net.ckpt')\n",
    "        else:     # use an existing model\n",
    "            saver.restore(sess, 'model/net.ckpt')\n",
    "            print(\"save success!\")\n",
    "\n",
    "        # Prediction\n",
    "        res = sess.run(fetches=y, feed_dict={xs: x_test})\n",
    "        new_res = []\n",
    "        for ele in res:\n",
    "            mmax = -1111\n",
    "            index = -1\n",
    "            for i in range(outsize):\n",
    "                if ele[i] > mmax:\n",
    "                    index, mmax  = i, ele[i]\n",
    "            new_res.append(index) \n",
    "        #print(new_res)\n",
    "        new_res = np.array(new_res)\n",
    "        counter = 0\n",
    "        for i in range(len(new_res)):\n",
    "          if (y_test[i] == new_res[i]):\n",
    "            counter += 1\n",
    "        #print(\"Accuracy: \", counter/len(new_res))\n",
    "        print(\"Accuracy: \", accuracy_score(y_test, new_res))\n",
    "\n",
    "def main():\n",
    "  #feature = read_feature('data/feature.txt')\n",
    "  #label = read_label('data/label.txt')\n",
    "\n",
    "  print(\"Loading data...\")\n",
    "  x_text, y = data_helpers.load_data_and_labels(\"data/sentence.txt\", \"data/label.txt\")\n",
    "\n",
    "  '''\n",
    "  outsize = 8\n",
    "  new_ydata = []\n",
    "  for i in range(len(y)):\n",
    "    new_ydata.append([0]*outsize)\n",
    "    new_ydata[i][y[i]] = 1\n",
    "    #print(new_ydata[i])\n",
    "  new_ydata = np.array(new_ydata)\n",
    "  y = new_ydata'''\n",
    "\n",
    "  # Build vocabulary\n",
    "  max_document_length = max([len(x.split(\" \")) for x in x_text])\n",
    "  vocab_processor = learn.preprocessing.VocabularyProcessor(max_document_length)\n",
    "  #feature = np.array(list(vocab_processor.fit_transform(x_text)))\n",
    "  #label = np.array(y)\n",
    "  x = np.array(list(vocab_processor.fit_transform(x_text)))\n",
    "\n",
    "  #print(x.shape)\n",
    "  #print(max_document_length)\n",
    "\n",
    "  # Randomly shuffle data\n",
    "  np.random.seed(10)\n",
    "  shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "\n",
    "  feature = np.array(x)[shuffle_indices]\n",
    "  label = np.array(y)[shuffle_indices]\n",
    "\n",
    "  x_train , x_test , y_train , y_test = train_test_split(feature, label, test_size = 0.1)\n",
    "  net(x_train, y_train, x_test, y_test)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cnn_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TextCNN(object):\n",
    "    \"\"\"\n",
    "    A CNN for text classification.\n",
    "    Uses an embedding layer, followed by a convolutional, max-pooling and softmax layer.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "      self, sequence_length, num_classes, vocab_size,\n",
    "      embedding_size, filter_sizes, num_filters, l2_reg_lambda=0.0):\n",
    "\n",
    "        # Placeholders for input, output and dropout\n",
    "        self.input_x = tf.placeholder(tf.int32, [None, sequence_length], name=\"input_x\")\n",
    "        self.input_y = tf.placeholder(tf.float32, [None, num_classes], name=\"input_y\")\n",
    "        self.dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n",
    "\n",
    "        # Keeping track of l2 regularization loss (optional)\n",
    "        l2_loss = tf.constant(0.0)\n",
    "\n",
    "        # Embedding layer\n",
    "        with tf.device('/cpu:0'), tf.name_scope(\"embedding\"):\n",
    "            self.W = tf.Variable(\n",
    "                tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0),\n",
    "                name=\"W\")\n",
    "            self.embedded_chars = tf.nn.embedding_lookup(self.W, self.input_x)\n",
    "            self.embedded_chars_expanded = tf.expand_dims(self.embedded_chars, -1)\n",
    "\n",
    "        # Create a convolution + maxpool layer for each filter size\n",
    "        pooled_outputs = []\n",
    "        for i, filter_size in enumerate(filter_sizes):\n",
    "            with tf.name_scope(\"conv-maxpool-%s\" % filter_size):\n",
    "                # Convolution Layer\n",
    "                filter_shape = [filter_size, embedding_size, 1, num_filters]\n",
    "                W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=\"W\")\n",
    "                b = tf.Variable(tf.constant(0.1, shape=[num_filters]), name=\"b\")\n",
    "                conv = tf.nn.conv2d(\n",
    "                    self.embedded_chars_expanded,\n",
    "                    W,\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding=\"VALID\",\n",
    "                    name=\"conv\")\n",
    "                # Apply nonlinearity\n",
    "                h = tf.nn.relu(tf.nn.bias_add(conv, b), name=\"relu\")\n",
    "                # Maxpooling over the outputs\n",
    "                pooled = tf.nn.max_pool(\n",
    "                    h,\n",
    "                    ksize=[1, sequence_length - filter_size + 1, 1, 1],\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding='VALID',\n",
    "                    name=\"pool\")\n",
    "                pooled_outputs.append(pooled)\n",
    "\n",
    "        # Combine all the pooled features\n",
    "        num_filters_total = num_filters * len(filter_sizes)\n",
    "        self.h_pool = tf.concat(pooled_outputs, 3)\n",
    "        self.h_pool_flat = tf.reshape(self.h_pool, [-1, num_filters_total])\n",
    "\n",
    "        # Add dropout\n",
    "        with tf.name_scope(\"dropout\"):\n",
    "            self.h_drop = tf.nn.dropout(self.h_pool_flat, self.dropout_keep_prob)\n",
    "\n",
    "        # Final (unnormalized) scores and predictions\n",
    "        with tf.name_scope(\"output\"):\n",
    "            W = tf.get_variable(\n",
    "                \"W\",\n",
    "                shape=[num_filters_total, num_classes],\n",
    "                initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[num_classes]), name=\"b\")\n",
    "            l2_loss += tf.nn.l2_loss(W)\n",
    "            l2_loss += tf.nn.l2_loss(b)\n",
    "            self.scores = tf.nn.xw_plus_b(self.h_drop, W, b, name=\"scores\")\n",
    "            self.predictions = tf.argmax(self.scores, 1, name=\"predictions\")\n",
    "\n",
    "        # Calculate mean cross-entropy loss\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            losses = tf.nn.softmax_cross_entropy_with_logits(logits=self.scores, labels=self.input_y)\n",
    "            self.loss = tf.reduce_mean(losses) + l2_reg_lambda * l2_loss\n",
    "\n",
    "        # Accuracy\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            correct_predictions = tf.equal(self.predictions, tf.argmax(self.input_y, 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### textCNN.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'flags'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-fb831260270f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Data loading params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dev_sample_percentage\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Percentage of the training data to use for validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"feature_file\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data/sentence.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"feature data (sentence).\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"label_file\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data/label.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label data (number).\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'flags'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import data_helpers\n",
    "#from cnn_model import TextCNN\n",
    "from tensorflow.contrib import learn\n",
    "\n",
    "# Parameters\n",
    "# ==================================================\n",
    "\n",
    "# Data loading params\n",
    "tf.flags.DEFINE_float(\"dev_sample_percentage\", 0.1, \"Percentage of the training data to use for validation\")\n",
    "tf.flags.DEFINE_string(\"feature_file\", \"data/sentence.txt\", \"feature data (sentence).\")\n",
    "tf.flags.DEFINE_string(\"label_file\", \"data/label.txt\", \"label data (number).\")\n",
    "\n",
    "# Model Hyperparameters\n",
    "tf.flags.DEFINE_integer(\"embedding_dim\", 100, \"Dimensionality of character embedding (default: 128)\")\n",
    "tf.flags.DEFINE_string(\"filter_sizes\", \"2,3,4,5\", \"Comma-separated filter sizes (default: '3,4,5')\")\n",
    "tf.flags.DEFINE_integer(\"num_filters\", 256, \"Number of filters per filter size (default: 128)\")\n",
    "tf.flags.DEFINE_float(\"dropout_keep_prob\", 0.5, \"Dropout keep probability (default: 0.5)\")\n",
    "tf.flags.DEFINE_float(\"l2_reg_lambda\", 0.0001, \"L2 regularization lambda (default: 0.0)\")\n",
    "\n",
    "# Training parameters\n",
    "tf.flags.DEFINE_integer(\"batch_size\", 120, \"Batch Size (default: 64)\")\n",
    "tf.flags.DEFINE_integer(\"num_epochs\", 20, \"Number of training epochs (default: 200)\")\n",
    "tf.flags.DEFINE_integer(\"evaluate_every\", 100, \"Evaluate model on dev set after this many steps (default: 100)\")\n",
    "tf.flags.DEFINE_integer(\"checkpoint_every\", 1, \"Save model after this many steps (default: 100)\")\n",
    "tf.flags.DEFINE_integer(\"num_checkpoints\", 5, \"Number of checkpoints to store (default: 5)\")\n",
    "# Misc Parameters\n",
    "tf.flags.DEFINE_boolean(\"allow_soft_placement\", True, \"Allow device soft device placement\")\n",
    "tf.flags.DEFINE_boolean(\"log_device_placement\", False, \"Log placement of ops on devices\")\n",
    "\n",
    "FLAGS = tf.flags.FLAGS\n",
    "FLAGS._parse_flags()\n",
    "print(\"\\nParameters:\")\n",
    "for attr, value in sorted(FLAGS.__flags.items()):\n",
    "    print(\"{}={}\".format(attr.upper(), value))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# Data Preparation\n",
    "# ==================================================\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "x_text, y = data_helpers.load_data_and_labels(FLAGS.feature_file, FLAGS.label_file)\n",
    "\n",
    "outsize = 6\n",
    "new_ydata = []\n",
    "for i in range(len(y)):\n",
    "  new_ydata.append([0]*outsize)\n",
    "  new_ydata[i][y[i]] = 1\n",
    "  #print(new_ydata[i])\n",
    "new_ydata = np.array(new_ydata)\n",
    "y = new_ydata\n",
    "\n",
    "# Build vocabulary\n",
    "max_document_length = max([len(x.split(\" \")) for x in x_text])\n",
    "vocab_processor = learn.preprocessing.VocabularyProcessor(max_document_length)\n",
    "x = np.array(list(vocab_processor.fit_transform(x_text)))\n",
    "\n",
    "print(x.shape)\n",
    "print(max_document_length)\n",
    "\n",
    "# Randomly shuffle data\n",
    "np.random.seed(10)\n",
    "shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "\n",
    "x_shuffled = np.array(x)[shuffle_indices]\n",
    "y_shuffled = np.array(y)[shuffle_indices]\n",
    "\n",
    "# Split train/test set\n",
    "# TODO: This is very crude, should use cross-validation\n",
    "dev_sample_index = -1 * int(FLAGS.dev_sample_percentage * float(len(y)))\n",
    "x_train, x_dev = x_shuffled[:dev_sample_index], x_shuffled[dev_sample_index:]\n",
    "y_train, y_dev = y_shuffled[:dev_sample_index], y_shuffled[dev_sample_index:]\n",
    "\n",
    "del x, y, x_shuffled, y_shuffled\n",
    "\n",
    "\n",
    "print(\"Vocabulary Size: {:d}\".format(len(vocab_processor.vocabulary_)))\n",
    "print(\"Train/Dev split: {:d}/{:d}\".format(len(y_train), len(y_dev)))\n",
    "\n",
    "\n",
    "# Training\n",
    "# ==================================================\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "config = tf.ConfigProto(allow_soft_placement=True)          #my modification\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "with tf.Graph().device('/gpu:3'):\n",
    "    session_conf = tf.ConfigProto(\n",
    "      allow_soft_placement=FLAGS.allow_soft_placement,\n",
    "      log_device_placement=FLAGS.log_device_placement)\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    with sess.as_default():\n",
    "        cnn = TextCNN(\n",
    "            sequence_length=x_train.shape[1],\n",
    "            num_classes=y_train.shape[1],\n",
    "            vocab_size=len(vocab_processor.vocabulary_),\n",
    "            embedding_size=FLAGS.embedding_dim,\n",
    "            filter_sizes=list(map(int, FLAGS.filter_sizes.split(\",\"))),\n",
    "            num_filters=FLAGS.num_filters,\n",
    "            l2_reg_lambda=FLAGS.l2_reg_lambda)\n",
    "\n",
    "        # Define Training procedure\n",
    "        global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "        optimizer = tf.train.AdamOptimizer(0.0001)\n",
    "        grads_and_vars = optimizer.compute_gradients(cnn.loss)\n",
    "        train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)\n",
    "\n",
    "        # Keep track of gradient values and sparsity (optional)\n",
    "        grad_summaries = []\n",
    "        for g, v in grads_and_vars:\n",
    "            if g is not None:\n",
    "                grad_hist_summary = tf.summary.histogram(\"{}/grad/hist\".format(v.name), g)\n",
    "                sparsity_summary = tf.summary.scalar(\"{}/grad/sparsity\".format(v.name), tf.nn.zero_fraction(g))\n",
    "                grad_summaries.append(grad_hist_summary)\n",
    "                grad_summaries.append(sparsity_summary)\n",
    "        grad_summaries_merged = tf.summary.merge(grad_summaries)\n",
    "\n",
    "        # Output directory for models and summaries\n",
    "        timestamp = str(int(time.time()))\n",
    "        #out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp))\n",
    "        #print(\"Writing to {}\\n\".format(out_dir))\n",
    "\n",
    "        # Summaries for loss and accuracy\n",
    "        loss_summary = tf.summary.scalar(\"loss\", cnn.loss)\n",
    "        acc_summary = tf.summary.scalar(\"accuracy\", cnn.accuracy)\n",
    "        saver = tf.train.Saver(tf.global_variables(), max_to_keep=FLAGS.num_checkpoints)\n",
    "\n",
    "        # Write vocabulary\n",
    "        #vocab_processor.save(os.path.join(out_dir, \"vocab\"))\n",
    "\n",
    "        # Initialize all variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        def train_step(x_batch, y_batch):\n",
    "            \"\"\"\n",
    "            A single training step\n",
    "            \"\"\"\n",
    "            feed_dict = {\n",
    "              cnn.input_x: x_batch,\n",
    "              cnn.input_y: y_batch,\n",
    "              cnn.dropout_keep_prob: FLAGS.dropout_keep_prob\n",
    "            }\n",
    "            _, step, loss, accuracy = sess.run(\n",
    "                [train_op, global_step, cnn.loss, cnn.accuracy],\n",
    "                feed_dict)\n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "            #train_summary_writer.add_summary(summaries, step)\n",
    "\n",
    "        def dev_step(x_batch, y_batch, writer=None):\n",
    "            \"\"\"\n",
    "            Evaluates model on a dev set\n",
    "            \"\"\"\n",
    "            feed_dict = {\n",
    "              cnn.input_x: x_batch,\n",
    "              cnn.input_y: y_batch,\n",
    "              cnn.dropout_keep_prob: 1\n",
    "            }\n",
    "            step, loss, accuracy = sess.run(\n",
    "                [global_step, cnn.loss, cnn.accuracy],\n",
    "                feed_dict)\n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "            #if writer:\n",
    "                #writer.add_summary(summaries, step)\n",
    "            return accuracy\n",
    "\n",
    "\n",
    "\n",
    "        is_train = False         \n",
    "\n",
    "        if is_train:\n",
    "            for kk in range(10):\n",
    "                # Generate batches\n",
    "                batches = data_helpers.batch_iter(\n",
    "                    list(zip(x_train, y_train)), FLAGS.batch_size, FLAGS.num_epochs)\n",
    "                # Training loop. For each batch...\n",
    "                for batch in batches:\n",
    "                    x_batch, y_batch = zip(*batch)\n",
    "                    train_step(x_batch, y_batch)\n",
    "                    current_step = tf.train.global_step(sess, global_step)\n",
    "                    if current_step % FLAGS.evaluate_every == 0:\n",
    "                        print(\"\\n\\n\\nEvaluation:\")\n",
    "                        test_acc = dev_step(x_dev, y_dev, writer=None)\n",
    "                        print(\"accuracy on test data is: {}\\n\\n\\n\".format(test_acc))\n",
    "                        saver.save(sess,'cnnmodel/net.ckpt')\n",
    "        else:\n",
    "            saver.restore(sess, 'cnnmodel/net.ckpt')\n",
    "            print(\"reload success!\")\n",
    "            test_acc = dev_step(x_dev, y_dev, writer=None)            \n",
    "            print(\"\\n\\nmodel accuracy on test data is: {}%\\n\\n\".format(test_acc*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
